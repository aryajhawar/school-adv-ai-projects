{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dspTTW3tAj2d"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# MNIST DIGIT CLASSIFIER (PyTorch)\n",
        "# -----------------------------\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 1. LOAD DATA\n",
        "# Transforms are preprocessing steps that get applied automatically to every image\n",
        "# you load from a dataset.\n",
        "# Think of transforms as a recipe that says:\n",
        "\n",
        "# “Every time you give me an image, do X, then Y, then Z to it.”\n",
        "# “For every MNIST image: convert it to a PyTorch tensor.\n",
        "# MNIST images come in as PIL images (Python Imaging Library).\n",
        "\n",
        "# But your neural network expects tensors.\n",
        "# -----------------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "KlCrgh9-Asn5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training dataset (MNIST)\n",
        "train_dataset = datasets.MNIST(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "cMXVcL0AA0lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eed3d05-2a56-4360-c253-6d4899240420"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 57.8MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.70MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.7MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.12MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test dataset\n",
        "test_dataset = datasets.MNIST(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")"
      ],
      "metadata": {
        "id": "veI7l5YTA3Ep"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# TODO: Access and print the unique labels in the training data set using the train_loader object\n",
        "num_outputs = train_dataset.classes\n",
        "print(num_outputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHIC8sa_A46H",
        "outputId": "3a453aaf-b242-4faf-9009-785a2c1eedb2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 2. DEFINE NEURAL NETWORK\n",
        "# TODO: Design a Neural Network with 1 hidden layer of 128 neurons\n",
        "# -----------------------------\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, n_features, n_hidden, n_outputs):\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO: Define layers\n",
        "        self.fc1 = nn.Linear(n_features, n_hidden)\n",
        "        self.fc2 = nn.Linear(n_hidden, n_hidden)\n",
        "        self.fc3 = nn.Linear(n_hidden, n_outputs)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten image: (batch, 1, 28, 28) → (batch, 784)\n",
        "        x = x.view(-1, 28*28)\n",
        "\n",
        "        # TODO: Add activation between layers\n",
        "        z1 = self.fc1(x)\n",
        "        z2 = self.fc2(z1)\n",
        "\n",
        "        # TODO: Output layer\n",
        "        output = self.fc3(z2)\n",
        "        return output\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "UXSW2wmAC0F1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Create the model\n",
        "\n",
        "model = SimpleNN(n_features = 784,n_hidden = 128, n_outputs = 10)"
      ],
      "metadata": {
        "id": "bikGj7NSDv6s"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 3. LOSS FUNCTION + OPTIMIZER\n",
        "# -----------------------------\n",
        "# TODO: Define your loss function\n",
        "loss_function =  loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "# TODO: Setup your gradient descent . Try different values for the learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.02, momentum=0.9)"
      ],
      "metadata": {
        "id": "zkCjk6WGEd0g"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 4. TRAINING LOOP\n",
        "# ------------------------------\n",
        "\n",
        "epochs = 200\n",
        "epochs_per_print = 10          # how many epochs to average over\n",
        "\n",
        "group_loss = 0.0               # accumulates loss over epochs in a group\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        # Backprop + update\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    # average loss for this epoch\n",
        "    avg_loss = total_loss / num_batches\n",
        "\n",
        "    # accumulate into 10-epoch group\n",
        "    group_loss += avg_loss\n",
        "\n",
        "    # every 10 epochs, print the average over those 10\n",
        "    if (epoch + 1) % epochs_per_print == 0:\n",
        "        group_avg_loss = group_loss / epochs_per_print\n",
        "        start_epoch = epoch + 1 - (epochs_per_print - 1)\n",
        "        end_epoch = epoch + 1\n",
        "        print(f\"Epochs {start_epoch}-{end_epoch}, Avg Loss: {group_avg_loss:.4f}\")\n",
        "\n",
        "        # reset for next group\n",
        "        group_loss = 0.0"
      ],
      "metadata": {
        "id": "3A9D4mHqEwJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        # TODO: Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Predicted class = index of max logit\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "id": "kmln8-n6ISxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "# -----------------------------\n",
        "# 6. TEST SINGLE PREDICTION\n",
        "# -----------------------------\n",
        "# -----------------------------\n",
        "# 6. TEST SINGLE PREDICTION\n",
        "# -----------------------------\n",
        "# ------------------------------\n",
        "# Gradio Sketchpad gives you:\n",
        "\n",
        "# * a full-color NumPy array\n",
        "\n",
        "# * black digit on white background\n",
        "\n",
        "# * large resolution\n",
        "\n",
        "# * no consistent scale\n",
        "#\n",
        "# Hence the preprocessing\n",
        "# ------------------------------\n",
        "\n",
        "def preprocess_image(image):\n",
        "    sketch_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),                      # NumPy → PIL\n",
        "    transforms.Grayscale(),                       # ensure 1 channel\n",
        "    transforms.Resize((28, 28)),                  # 28x28 like MNIST\n",
        "    transforms.Lambda(lambda img: ImageOps.invert(img)),  # invert colors\n",
        "    transforms.ToTensor(),                        # → tensor, shape (1,28,28), values in [0,1]\n",
        "    ])\n",
        "    # Gradio Sketchpad sometimes passes a dict with 'composite'\n",
        "    if isinstance(image, dict):\n",
        "        image = image['composite']   # this is a NumPy array\n",
        "\n",
        "    # Apply the preprocessing transform\n",
        "    img_tensor = sketch_transform(image)  # (1, 28, 28)\n",
        "\n",
        "    # Add batch dimension → (1, 1, 28, 28)\n",
        "    img_tensor = img_tensor.unsqueeze(0)\n",
        "\n",
        "    return img_tensor\n",
        "\n",
        "def predict_digit(image):\n",
        "    # --- STEP 1: CHECK IF SOMETHING HAS BEEN DRAWN ---\n",
        "    if image is None: return \"Draw something!\"\n",
        "\n",
        "    # --- STEP 2: PREPROCESS THE IMAGE ---\n",
        "    img_tensor = preprocess_image(image)\n",
        "\n",
        "    # --- STEP 3: RUN THE MODEL ---\n",
        "    with torch.no_grad():\n",
        "        prediction = model(img_tensor)\n",
        "\n",
        "        # Get the index of the highest score (the predicted digit)\n",
        "        predicted_digit = torch.argmax(prediction).item()\n",
        "\n",
        "    return str(predicted_digit)\n",
        "\n",
        "# UI Setup\n",
        "interface = gr.Interface(fn=predict_digit, inputs=gr.Sketchpad(label=\"Draw Here\"), outputs=\"label\")\n",
        "interface.queue().launch()"
      ],
      "metadata": {
        "id": "fz--q3dCIVs2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}